# -*- coding: utf-8 -*-
"""Copy of Simple Classification Model using Keras on Colab TPU.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C030UvXpPFAbPXNdIxsRheYYx2Dmh9qa

# A simple classification model using Keras with Cloud TPUs

:) Away due holidays don't have any deep learning rig nearby

###Imports
"""

#  Copyright 2019 Kiril Cvetkov. All Rights Reserved.


import json
import os
import pandas as pd
import pprint
import tensorflow as tf
import time
import numpy as np
from tensorflow import keras
from tensorflow.keras.layers import *

print(tf.__version__)

"""###Resolve TPU Address

###Training of the model on TPU
"""

class ConvBnAct(tf.keras.Model):
  
  def __init__(self, n_filters=64, kernel=(2,2), strides=(1,1)):
    self.filters = n_filters
    self.kernel = kernel
    self.strides = strides
    self.activation = tf.nn.relu
    super(ConvBnAct, self).__init__(name='')
    
    self.conv_ =  Conv2D(filters=self.filters,
                  kernel_size = self.kernel,
                  strides = self.strides, name='Conv2D')
    
    self.batch_norm = BatchNormalization(name='BatchNorm')
    
    self.activation = Activation(self.activation, name='RELU')
  def call(self, x, training=False):
    x = self.conv_(x) 
    x = self.batch_norm(x)
    
    x = self.activation(x)
    
    return x

norm = tf.random_normal([10, 256, 256, 64], mean=-1, stddev=4)

block = ConvBnAct()
block(norm)

print([x.name for x in block.variables])

class ConvAct(tf.keras.Model):
    def __init__(self, n_filters, kernel=(1,1), activation = tf.nn.relu, pooling=False):
      super(ConvAct, self).__init__(name='')

      self.pooling = pooling
      self.kernel = kernel
      self.n_filters = n_filters
      self.activation = activation
      self.pooling = pooling


      self.poolingLayer = AveragePooling2D(pool_size=(1,1), padding='same', name='AveragePool')
      self.convLayer = Conv2D(filters = self.n_filters,
                         kernel_size = self.kernel,
                         strides=1, name='Conv2D')

      self.activation = Activation(activation, name='ActivationRelu')

    def call(self, x, training = False):

      if self.pooling:
        x = self.poolingLayer(x)

      x = self.convLayer(x)
      x = self.activation(x)

      return x

norm = tf.random_normal([10, 127, 127, 64], mean=-1, stddev=4)

block = ConvAct(n_filters=64, pooling=True)
block(norm)

print([x.name for x in block.variables])

class AttentionRefinmentModule(tf.keras.Model):
  def __init__(self, n_filters):
    super(AttentionRefinmentModule, self).__init__(name='')

    self.filters = n_filters
    
    self.poolingLayer = AveragePooling2D(pool_size = (1,1), padding='same', name='AveragePool')
    self.conv_bn_act = ConvBnAct(kernel = (1,1), n_filters = self.filters)
    
    
  def call(self, inputs, training = False):
    x = self.poolingLayer(inputs)
    x = self.conv_bn_act(x)
    
    print(x.shape)
    print(inputs.shape)
    return tf.math.multiply(inputs,x)

norm = tf.random_normal([10, 256, 256, 64], mean=-1, stddev=4)

block = AttentionRefinmentModule(n_filters=64)
block(norm)

print([x.name for x in block.variables])

class FeatureFusionModule(tf.keras.Model):
  def __init__(self, n_filters):
    super(FeatureFusionModule, self).__init__(name='')
    self.conv_bn_act = ConvBnAct(n_filters=n_filters, kernel=(3, 3), strides=2)
    self.conv_act1 = ConvAct(n_filters=n_filters, pooling=True)
    self.conv_act2 = ConvAct(n_filters=n_filters, pooling=False, activation = tf.nn.sigmoid)
    activation = tf.nn.sigmoid
    
   
  def call(self, input_f, input_s, training=True):
    
    print(input_f.shape, input_s.shape)
    concate = Concatenate(axis=-1)([input_f, input_s])
    
    print(concate.shape)
    branch0 = self.conv_bn_act(concate)
    print(branch0.shape)
    branch_1 = self.conv_act1(branch0)
    
    branch_1 = self.conv_act2(branch_1)
    
    x = multiply([branch0, branch_1])
    return  Add()([branch0, x])

norm1 = tf.random_normal([10, 256, 256, 64], mean=-1, stddev=4)
norm2 = tf.random_normal([10, 256, 256, 64], mean=-1, stddev=4)

block = FeatureFusionModule(n_filters=64)
block(norm1, norm2)

print([x.name for x in block.variables])

norm1 = tf.random_normal([10, 256, 256, 64], mean=-1, stddev=4)
print(GlobalMaxPooling2D()(norm1).shape)

class ContextPath(tf.keras.Model):
  def __init__(self, n_filters):
    super(ContextPath, self).__init__(name='')
    
    self.globalmax = GlobalMaxPooling2D()
    self.upsample_1 = UpSampling2D(size=(2, 2))
    self.upsample_2 = UpSampling2D(size=(2, 2))
    self.upsample_3 = UpSampling2D(size=(2, 2))
    self.upsample_4 = UpSampling2D(size=(2, 2))
    self.arm1 = AttentionRefinmentModule(n_filters=64)
    self.arm2 = AttentionRefinmentModule(n_filters=64)

  def call(self, tail_layer):
    globalmax = self.globalmax(tail_layer)
    upsample1 = self.upsample_1(tail_layer)
    upsample2 = self.upsample_2(upsample1)
    upsample3 = self.upsample_3(upsample2)
    upsample4 = self.upsample_4(upsample3)

    seg1 = self.arm1(upsample3)
    seg2 = self.arm2(upsample4)


    tail = Add()([upsample4, globalmax])

    cnc = Concatenate(axis=-1)([tail,seg2])

    final_feature = Concatenate(axis=-1)([cnc, seg2])
    return final_feature

tail_layer = tf.random_normal([10, 256, 256, 64], mean=-1, stddev=4)
block = ContextPath(n_filters=64)
block(tail_layer)

class FinalModel(tf.keras.Model):
  def __init__(self):
    self.context_path = ContextPath(64)
    self.batch1 = ConvBnAct(64)
    self.batch2 = ConvBnAct(128)
    self.batch3 = ConvBnAct(256)
    self.upsample = UpSampling2D(size=(8, 8))
    self.feature_fusion = FeatureFusionModel(64)
    
  def call(self, x, last_layer): 
    
    #spatial path
    x = self.batch1(x)
    x = self.batch2(x)
    x = self.batch3(x)
    
    #context path
    cp = ContextPath(last_layer)
    
    #concatenate
    ffm = Concatenate(axis=-1)([cp,x])
    
    #upsample
    ans = self.upsample(ffm)
    
    return ans

